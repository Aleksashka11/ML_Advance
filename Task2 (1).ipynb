{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>company</th>\n",
       "      <th>is_local</th>\n",
       "      <th>type</th>\n",
       "      <th>fin_1</th>\n",
       "      <th>fin_2</th>\n",
       "      <th>fin_3</th>\n",
       "      <th>fin_4</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>160000</td>\n",
       "      <td>39.284310</td>\n",
       "      <td>-76.735350</td>\n",
       "      <td>18187</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>113033.389907</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>270.906219</td>\n",
       "      <td>31222.780176</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>160001</td>\n",
       "      <td>36.758509</td>\n",
       "      <td>-76.344861</td>\n",
       "      <td>11208</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-87239.590275</td>\n",
       "      <td>73759.387510</td>\n",
       "      <td>759.194862</td>\n",
       "      <td>237587.544996</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>160002</td>\n",
       "      <td>43.402802</td>\n",
       "      <td>-75.217100</td>\n",
       "      <td>7437</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>-122084.498620</td>\n",
       "      <td>15528.109943</td>\n",
       "      <td>1039.655934</td>\n",
       "      <td>29612.346982</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>160003</td>\n",
       "      <td>41.871160</td>\n",
       "      <td>-87.848570</td>\n",
       "      <td>17362</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>87355.127256</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>214.594205</td>\n",
       "      <td>163526.475818</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>160004</td>\n",
       "      <td>42.161296</td>\n",
       "      <td>-88.129184</td>\n",
       "      <td>11515</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>33014.437946</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>379.819724</td>\n",
       "      <td>67499.397999</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   latitude  longitude  company  is_local  type          fin_1  \\\n",
       "0      160000  39.284310 -76.735350    18187         1     1  113033.389907   \n",
       "1      160001  36.758509 -76.344861    11208         0     0  -87239.590275   \n",
       "2      160002  43.402802 -75.217100     7437         1     4 -122084.498620   \n",
       "3      160003  41.871160 -87.848570    17362         0     1   87355.127256   \n",
       "4      160004  42.161296 -88.129184    11515         0     3   33014.437946   \n",
       "\n",
       "          fin_2        fin_3          fin_4  target  \n",
       "0      0.000000   270.906219   31222.780176       0  \n",
       "1  73759.387510   759.194862  237587.544996       1  \n",
       "2  15528.109943  1039.655934   29612.346982       0  \n",
       "3      0.000000   214.594205  163526.475818       1  \n",
       "4      0.000000   379.819724   67499.397999       1  "
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv('test.csv')\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>company</th>\n",
       "      <th>is_local</th>\n",
       "      <th>type</th>\n",
       "      <th>fin_1</th>\n",
       "      <th>fin_2</th>\n",
       "      <th>fin_3</th>\n",
       "      <th>fin_4</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.10891</td>\n",
       "      <td>-83.09286</td>\n",
       "      <td>8336</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-135060.089443</td>\n",
       "      <td>86013.396489</td>\n",
       "      <td>1206.094242</td>\n",
       "      <td>52287.082257</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>39.86542</td>\n",
       "      <td>-84.06280</td>\n",
       "      <td>18403</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1766.845055</td>\n",
       "      <td>14985.640180</td>\n",
       "      <td>477.494992</td>\n",
       "      <td>168836.215743</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>39.10266</td>\n",
       "      <td>-84.52468</td>\n",
       "      <td>14022</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-177302.873693</td>\n",
       "      <td>44881.958005</td>\n",
       "      <td>1463.339889</td>\n",
       "      <td>130388.243325</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>39.10148</td>\n",
       "      <td>-84.52341</td>\n",
       "      <td>11051</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>209049.997460</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>95.340075</td>\n",
       "      <td>103267.727546</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>41.06213</td>\n",
       "      <td>-81.53784</td>\n",
       "      <td>3243</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8669.269507</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>399.421926</td>\n",
       "      <td>177532.206618</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  latitude  longitude  company  is_local  type          fin_1  \\\n",
       "0           0  40.10891  -83.09286     8336         0     3 -135060.089443   \n",
       "1           1  39.86542  -84.06280    18403         1     0   -1766.845055   \n",
       "2           2  39.10266  -84.52468    14022         0     3 -177302.873693   \n",
       "3           3  39.10148  -84.52341    11051         0     0  209049.997460   \n",
       "4           4  41.06213  -81.53784     3243         0     3    8669.269507   \n",
       "\n",
       "          fin_2        fin_3          fin_4  target  \n",
       "0  86013.396489  1206.094242   52287.082257       0  \n",
       "1  14985.640180   477.494992  168836.215743       1  \n",
       "2  44881.958005  1463.339889  130388.243325       0  \n",
       "3      0.000000    95.340075  103267.727546       1  \n",
       "4      0.000000   399.421926  177532.206618       1  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('train.csv')\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding, Input, Flatten, Dense, BatchNormalization, Concatenate, Reshape\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3683\n"
     ]
    }
   ],
   "source": [
    "#replacing companies that have <= 10 units with -1 \n",
    "train_data.loc[train_data.company <= 10, ('company')] = -1\n",
    "print(train_data['company'].unique().size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clustering units by geographical location\n",
    "features = train_data[['latitude', 'longitude']]\n",
    "from sklearn.cluster import KMeans\n",
    "kmeans_clustering = KMeans(\n",
    "    init=\"random\",\n",
    "    n_clusters=300,\n",
    "    n_init=10,\n",
    "    max_iter=300,\n",
    "    random_state=42\n",
    ")\n",
    "kmeans_clustering.fit(features)\n",
    "labels = kmeans_clustering.labels_\n",
    "train_data['cluster'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_input = Input(shape=(5, ), name='features')\n",
    "company_input = Input(shape=(1, ), name='company')\n",
    "type_input = Input(shape=(1, ), name='type')\n",
    "location_input = Input(shape=(1, ), name='location')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160001"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['type'].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing companies that have <= 10 units with -1 \n",
    "#train_data.loc[train_data.company <= 10, ('company')] = -1\n",
    "company_input = Input(shape=(1, ), name='company')\n",
    "company_features = Embedding(3683, 64)(company_input)\n",
    "company_features = Dense(32, activation=\"relu\")(company_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data['type'].unique().size\n",
    "type_features = Embedding(train_data['type'].unique().size, 8)(type_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_features = Dense(32, activation=\"relu\")(data_input)\n",
    "data_features = BatchNormalization()(data_features)\n",
    "data_features = Dense(32, activation=\"relu\")(data_input)\n",
    "data_features = BatchNormalization()(data_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160001\n"
     ]
    }
   ],
   "source": [
    "#clustering units by geographical location\n",
    "features = train_data[['latitude', 'longitude']]\n",
    "from sklearn.cluster import KMeans\n",
    "kmeans_clustering = KMeans(\n",
    "    init=\"random\",\n",
    "    n_clusters=300,\n",
    "    n_init=10,\n",
    "    max_iter=300,\n",
    "    random_state=42\n",
    ")\n",
    "kmeans_clustering.fit(features)\n",
    "labels = kmeans_clustering.labels_\n",
    "train_data['cluster'] = labels\n",
    "print(train_data['cluster'].size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_features = Embedding(300, 32)(location_input)\n",
    "location_features = Dense(32, activation=\"relu\")(location_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tensorflow.keras import layers\n",
    "#feat_conc = Concatenate()([data_features, company_features, type_features, location_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feat_conc = Dense(64)(feat_conc)\n",
    "#feat_conc = BatchNormalization()(feat_conc)\n",
    "#feat_conc = Dense(64)(feat_conc)\n",
    "#feat_conc = BatchNormalization()(feat_conc)\n",
    "#feat_conc = Dense(1)(feat_conc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "features (InputLayer)           [(None, 1, 4)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "company (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "location (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_68 (Dense)                (None, 1, 32)        160         features[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_17 (Embedding)        (None, 1, 64)        10240064    company[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "type (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_19 (Embedding)        (None, 1, 32)        5120032     location[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 1, 32)        128         dense_68[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_66 (Dense)                (None, 1, 32)        2080        embedding_17[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "embedding_18 (Embedding)        (None, 1, 8)         1280008     type[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense_69 (Dense)                (None, 1, 32)        1056        embedding_19[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_36 (Concatenate)    (None, 1, 104)       0           batch_normalization_35[0][0]     \n",
      "                                                                 dense_66[0][0]                   \n",
      "                                                                 embedding_18[0][0]               \n",
      "                                                                 dense_69[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_70 (Dense)                (None, 1, 64)        6720        concatenate_36[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 1, 64)        256         dense_70[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_71 (Dense)                (None, 1, 64)        4160        batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 1, 64)        256         dense_71[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_72 (Dense)                (None, 1, 1)         65          batch_normalization_37[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 16,654,985\n",
      "Trainable params: 16,654,665\n",
      "Non-trainable params: 320\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "#model = keras.Model(inputs=[data_input, company_input, type_input, location_input], outputs = [feat_conc])\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = keras.Model(inputs=[data_input, company_input, type_input, location_input], outputs=[data_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_13\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "features (InputLayer)           [(None, 4)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_79 (Dense)                (None, 32)           160         features[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "company (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "type (InputLayer)               [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "location (InputLayer)           [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 32)           128         dense_79[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 288\n",
      "Trainable params: 224\n",
      "Non-trainable params: 64\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = keras.Model(inputs=[data_input, company_input, type_input, location_input], outputs=[company_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_9\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "company (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_20 (Embedding)        (None, 1, 64)        10240064    company[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "features (InputLayer)           [(None, 4)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "type (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "location (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_73 (Dense)                (None, 1, 32)        2080        embedding_20[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 10,242,144\n",
      "Trainable params: 10,242,144\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = keras.Model(inputs=[data_input, company_input, type_input, location_input], outputs=[type_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_10\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "type (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "features (InputLayer)           [(None, 4)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "company (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "location (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_21 (Embedding)        (None, 1, 8)         1280008     type[0][0]                       \n",
      "==================================================================================================\n",
      "Total params: 1,280,008\n",
      "Trainable params: 1,280,008\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = keras.Model(inputs=[data_input, company_input, type_input, location_input], outputs=[location_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_12\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "location (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_22 (Embedding)        (None, 1, 32)        5120032     location[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "features (InputLayer)           [(None, 4)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "company (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "type (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_76 (Dense)                (None, 1, 32)        1056        embedding_22[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 5,121,088\n",
      "Trainable params: 5,121,088\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "Tensor(\"dense_81/Identity:0\", shape=(None, 1, 32), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(type(company_features))\n",
    "print(company_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "reshaped_company_features = tf.reshape(company_features, [-1, 32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [],
   "source": [
    "reshaped_type_features = tf.reshape(type_features, [-1, 8])\n",
    "reshaped_location_features = tf.reshape(location_features, [-1, 32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "feat_conc = Concatenate()([data_features, reshaped_company_features, reshaped_type_features, reshaped_location_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_conc = Dense(64, activation=\"relu\")(feat_conc)\n",
    "feat_conc = BatchNormalization()(feat_conc)\n",
    "feat_conc = Dense(64, activation=\"relu\")(feat_conc)\n",
    "feat_conc = BatchNormalization()(feat_conc)\n",
    "feat_conc = Dense(1, name=\"targets\", activation=\"relu\")(feat_conc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_23\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "company (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "location (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "features (InputLayer)           [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_45 (Embedding)        (None, 1, 64)        235712      company[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "type (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_44 (Embedding)        (None, 1, 32)        9600        location[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_126 (Dense)               (None, 32)           192         features[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_130 (Dense)               (None, 1, 32)        2080        embedding_45[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "embedding_43 (Embedding)        (None, 1, 8)         40          type[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense_127 (Dense)               (None, 1, 32)        1056        embedding_44[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 32)           128         dense_126[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_36 (TensorF [(None, 32)]         0           dense_130[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_37 (TensorF [(None, 8)]          0           embedding_43[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_38 (TensorF [(None, 32)]         0           dense_127[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_45 (Concatenate)    (None, 104)          0           batch_normalization_69[0][0]     \n",
      "                                                                 tf_op_layer_Reshape_36[0][0]     \n",
      "                                                                 tf_op_layer_Reshape_37[0][0]     \n",
      "                                                                 tf_op_layer_Reshape_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_131 (Dense)               (None, 64)           6720        concatenate_45[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 64)           256         dense_131[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_132 (Dense)               (None, 64)           4160        batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 64)           256         dense_132[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "targets (Dense)                 (None, 1)            65          batch_normalization_73[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 260,265\n",
      "Trainable params: 259,945\n",
      "Non-trainable params: 320\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "model = keras.Model(inputs=[data_input, company_input, type_input, location_input], outputs = [feat_conc])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.loc[train_data.company <= 10, ('company')] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = test_data[['fin_1', 'fin_2', 'fin_3', 'fin_4', 'is_local']].values\n",
    "company = test_data['company'].unique()\n",
    "types = test_data['type'].unique()\n",
    "#targets = test_data['target'].values[:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_2 = test_data[['latitude', 'longitude']]\n",
    "from sklearn.cluster import KMeans\n",
    "kmeans_clustering = KMeans(\n",
    "    init=\"random\",\n",
    "    n_clusters=300,\n",
    "    n_init=10,\n",
    "    max_iter=300,\n",
    "    random_state=42\n",
    ")\n",
    "kmeans_clustering.fit(features_2)\n",
    "labels = kmeans_clustering.labels_\n",
    "test_data['cluster'] = labels\n",
    "location = test_data['cluster'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(1e-3),\n",
    "    loss=[\n",
    "        keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Data cardinality is ambiguous:\n  x sizes: 40000, 2970, 5, 40000\nPlease provide data which shares the same first dimension.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-470-d2dcdc211c4d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;31m#{\"targets\": targets},\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m )\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    233\u001b[0m           \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 235\u001b[1;33m           use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    236\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_data_adapter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36m_process_training_inputs\u001b[1;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, steps_per_epoch, validation_split, validation_data, validation_steps, shuffle, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    591\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 593\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    594\u001b[0m     \u001b[0mval_adapter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[1;34m(model, mode, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    704\u001b[0m       \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    705\u001b[0m       \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 706\u001b[1;33m       use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    708\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0madapter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[0;32m    269\u001b[0m             label, \", \".join([str(i.shape[0]) for i in nest.flatten(data)]))\n\u001b[0;32m    270\u001b[0m       \u001b[0mmsg\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m\"Please provide data which shares the same first dimension.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 271\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    272\u001b[0m     \u001b[0mnum_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Data cardinality is ambiguous:\n  x sizes: 40000, 2970, 5, 40000\nPlease provide data which shares the same first dimension."
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    {\"features\": features, \"company\": company, \"type\": types, \"location\": location},\n",
    "    #{\"targets\": targets},\n",
    "    epochs=10,\n",
    "    batch_size=128,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2939\n"
     ]
    }
   ],
   "source": [
    "print(company.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_mapping = {num:val for num, val in enumerate(company)}\n",
    "type_mapping = {num:val for num, val in enumerate(types)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 18187, 1: 11208, 2: 7437, 3: 17362, 4: 11515, 5: 8562, 6: 13600, 7: 16654, 8: 547, 9: 6401, 10: 4650, 11: 6925, 12: 16190, 13: 8755, 14: 7465, 15: 10589, 16: 5237, 17: 12287, 18: 700, 19: 7560, 20: 9825, 21: 10208, 22: 1265, 23: 16144, 24: 8516, 25: 9384, 26: 18485, 27: 13595, 28: 13365, 29: 18478, 30: 19493, 31: 7576, 32: 10769, 33: 381, 34: 15111, 35: 17193, 36: 3466, 37: 8747, 38: 11960, 39: 17102, 40: 11849, 41: 14022, 42: 4528, 43: 1196, 44: 11671, 45: 1305, 46: 17997, 47: 10737, 48: 3377, 49: 6575, 50: 8822, 51: 11101, 52: 18033, 53: 375, 54: 5569, 55: 15581, 56: 9332, 57: 1, 58: 12517, 59: 852, 60: 10892, 61: 12431, 62: 18246, 63: 6632, 64: 11137, 65: 1007, 66: 17846, 67: 17323, 68: 5166, 69: 12975, 70: 6, 71: 6416, 72: 1254, 73: 6463, 74: 7451, 75: 15717, 76: 17008, 77: 2360, 78: 4067, 79: 3243, 80: 11307, 81: 5838, 82: 542, 83: 19105, 84: 15447, 85: 14049, 86: 12524, 87: 6648, 88: 7445, 89: 19140, 90: 13199, 91: 1473, 92: 9540, 93: 16260, 94: 6966, 95: 4515, 96: 4358, 97: 12071, 98: 10755, 99: 13236, 100: 19773, 101: 7049, 102: 9490, 103: 11701, 104: 19020, 105: 12429, 106: 11, 107: 7064, 108: 6378, 109: 4591, 110: 14615, 111: 6797, 112: 13578, 113: 11789, 114: 2989, 115: 17150, 116: 1483, 117: 16168, 118: 12136, 119: 2286, 120: 13824, 121: 16110, 122: 19275, 123: 18164, 124: 8336, 125: 1187, 126: 13982, 127: 4898, 128: 8299, 129: 5928, 130: 109, 131: 1504, 132: 10064, 133: 12950, 134: 11410, 135: 16101, 136: 441, 137: 9217, 138: 1854, 139: 16985, 140: 10445, 141: 7790, 142: 19879, 143: 15272, 144: 5909, 145: 6462, 146: 3228, 147: 9265, 148: 19547, 149: 10331, 150: 1242, 151: 13825, 152: 6271, 153: 6324, 154: 3548, 155: 17780, 156: 18403, 157: 13335, 158: 10083, 159: 6674, 160: 19835, 161: 8917, 162: 5792, 163: 3070, 164: 4803, 165: 2810, 166: 1687, 167: 12898, 168: 3856, 169: 5143, 170: 1622, 171: 13736, 172: 11203, 173: 3239, 174: 14127, 175: 14933, 176: 16887, 177: 19702, 178: 9181, 179: 1349, 180: 3492, 181: 575, 182: 1256, 183: 1876, 184: 18178, 185: 12858, 186: 3454, 187: 2148, 188: 17502, 189: 163, 190: 6828, 191: 12364, 192: 8447, 193: 13546, 194: 14849, 195: 5469, 196: 4501, 197: 18004, 198: 571, 199: 4641, 200: 14733, 201: 18091, 202: 10547, 203: 12662, 204: 16906, 205: 7891, 206: 10772, 207: 3654, 208: 8552, 209: 11645, 210: 5140, 211: 18647, 212: 7893, 213: 8338, 214: 8517, 215: 17803, 216: 16518, 217: 4407, 218: 10977, 219: 367, 220: 17305, 221: 18752, 222: 7509, 223: 6296, 224: 4913, 225: 97, 226: 4625, 227: 11088, 228: 10290, 229: 13295, 230: 16820, 231: 8873, 232: 6705, 233: 16936, 234: 10565, 235: 5971, 236: 10978, 237: 5336, 238: 8232, 239: 16868, 240: 8033, 241: 7947, 242: 19208, 243: 68, 244: 7566, 245: 3902, 246: 4271, 247: 695, 248: 5393, 249: 5348, 250: 15601, 251: 13288, 252: 10472, 253: 14633, 254: 2288, 255: 4074, 256: 17122, 257: 11204, 258: 8506, 259: 793, 260: 681, 261: 6970, 262: 13047, 263: 10584, 264: 10888, 265: 16174, 266: 8399, 267: 3656, 268: 15831, 269: 13005, 270: 4537, 271: 14768, 272: 14590, 273: 2484, 274: 2938, 275: 15410, 276: 2234, 277: 76, 278: 13356, 279: 612, 280: 3821, 281: 18844, 282: 8756, 283: 6621, 284: 4758, 285: 15750, 286: 3253, 287: 14895, 288: 17216, 289: 3862, 290: 14183, 291: 2365, 292: 6505, 293: 14061, 294: 8300, 295: 17451, 296: 7040, 297: 13744, 298: 11019, 299: 11996, 300: 6644, 301: 4275, 302: 9011, 303: 4776, 304: 19457, 305: 6262, 306: 14780, 307: 19576, 308: 16827, 309: 13722, 310: 12173, 311: 3439, 312: 8092, 313: 16874, 314: 11467, 315: 3434, 316: 3995, 317: 17441, 318: 11244, 319: 17227, 320: 9200, 321: 17693, 322: 3783, 323: 302, 324: 7133, 325: 3605, 326: 11922, 327: 286, 328: 1286, 329: 12821, 330: 7123, 331: 4121, 332: 16663, 333: 6471, 334: 19149, 335: 11858, 336: 7855, 337: 7345, 338: 1223, 339: 14793, 340: 12177, 341: 12788, 342: 7058, 343: 11087, 344: 12991, 345: 16275, 346: 19059, 347: 14461, 348: 2086, 349: 13603, 350: 7553, 351: 8711, 352: 11818, 353: 19974, 354: 4583, 355: 10704, 356: 447, 357: 13693, 358: 2071, 359: 2400, 360: 10437, 361: 11759, 362: 4504, 363: 13125, 364: 8911, 365: 18358, 366: 12266, 367: 7938, 368: 9852, 369: 5421, 370: 19396, 371: 3898, 372: 15091, 373: 753, 374: 9920, 375: 17408, 376: 7877, 377: 8165, 378: 8689, 379: 13042, 380: 3987, 381: 10116, 382: 6239, 383: 5736, 384: 5570, 385: 3938, 386: 18370, 387: 8514, 388: 12454, 389: 11516, 390: 6233, 391: 3892, 392: 9059, 393: 1865, 394: 6426, 395: 17244, 396: 10491, 397: 10813, 398: 4880, 399: 8567, 400: 6537, 401: 4963, 402: 11843, 403: 8942, 404: 8175, 405: 18233, 406: 13637, 407: 13079, 408: 16179, 409: 4618, 410: 1311, 411: 6182, 412: 12794, 413: 17263, 414: 12653, 415: 94, 416: 1698, 417: 12232, 418: 2576, 419: 726, 420: 4708, 421: 11287, 422: 18813, 423: 16579, 424: 11015, 425: 3920, 426: 13342, 427: 18182, 428: 6901, 429: 9018, 430: 11508, 431: 9398, 432: 14960, 433: 13515, 434: 16782, 435: 12292, 436: 519, 437: 9321, 438: 13512, 439: 12112, 440: 18354, 441: 17314, 442: 13698, 443: 14145, 444: 1744, 445: 6848, 446: 8746, 447: 19784, 448: 497, 449: 15428, 450: 10814, 451: 8180, 452: 10405, 453: 8965, 454: 8986, 455: 17809, 456: 10302, 457: 15860, 458: 1283, 459: 19863, 460: 841, 461: 2557, 462: 14628, 463: 17814, 464: 14119, 465: 8801, 466: 17989, 467: 19924, 468: 17905, 469: 7, 470: 18357, 471: 30, 472: 1202, 473: 11544, 474: 15282, 475: 15878, 476: 1846, 477: 13136, 478: 2326, 479: 2811, 480: 4530, 481: 15603, 482: 3363, 483: 7164, 484: 340, 485: 13739, 486: 12799, 487: 17293, 488: 13070, 489: 6954, 490: 10497, 491: 2422, 492: 18127, 493: 6015, 494: 10545, 495: 624, 496: 7434, 497: 477, 498: 4045, 499: 7612, 500: 1718, 501: 3104, 502: 19910, 503: 17737, 504: 8302, 505: 17697, 506: 12007, 507: 3497, 508: 17700, 509: 8569, 510: 17466, 511: 1205, 512: 9028, 513: 3160, 514: 11367, 515: 12425, 516: 13463, 517: 12374, 518: 2191, 519: 14284, 520: 9707, 521: 5517, 522: 17470, 523: 11164, 524: 17281, 525: 14563, 526: 4357, 527: 8595, 528: 4035, 529: 3954, 530: 11974, 531: 351, 532: 19006, 533: 19919, 534: 13111, 535: 4061, 536: 14846, 537: 17378, 538: 9113, 539: 18797, 540: 8210, 541: 4592, 542: 18204, 543: 19878, 544: 2301, 545: 14467, 546: 8383, 547: 13912, 548: 6423, 549: 4853, 550: 4968, 551: 2316, 552: 18938, 553: 418, 554: 18126, 555: 3482, 556: 16615, 557: 11447, 558: 13556, 559: 9518, 560: 9846, 561: 16843, 562: 8479, 563: 18648, 564: 8967, 565: 9680, 566: 9420, 567: 9740, 568: 6592, 569: 5257, 570: 13152, 571: 9916, 572: 1017, 573: 569, 574: 6407, 575: 1094, 576: 12715, 577: 5111, 578: 1962, 579: 9697, 580: 1769, 581: 522, 582: 15723, 583: 4695, 584: 8836, 585: 4011, 586: 6855, 587: 2424, 588: 8076, 589: 10102, 590: 2359, 591: 13397, 592: 17120, 593: 5343, 594: 6042, 595: 16506, 596: 9036, 597: 18424, 598: 185, 599: 18762, 600: 10423, 601: 15910, 602: 10980, 603: 15814, 604: 11390, 605: 18261, 606: 4083, 607: 192, 608: 19359, 609: 9323, 610: 9402, 611: 3823, 612: 9597, 613: 14641, 614: 12392, 615: 2660, 616: 8105, 617: 2054, 618: 4090, 619: 2593, 620: 12861, 621: 2953, 622: 15863, 623: 8555, 624: 17945, 625: 8186, 626: 14177, 627: 11051, 628: 10124, 629: 7056, 630: 1140, 631: 12874, 632: 8640, 633: 9620, 634: 3533, 635: 16886, 636: 2934, 637: 2997, 638: 8047, 639: 8254, 640: 19074, 641: 7759, 642: 7918, 643: 6961, 644: 8948, 645: 4216, 646: 15911, 647: 9661, 648: 9427, 649: 7141, 650: 670, 651: 18224, 652: 1251, 653: 3742, 654: 4736, 655: 9692, 656: 824, 657: 7674, 658: 3446, 659: 19191, 660: 11136, 661: 19016, 662: 1664, 663: 13626, 664: 16489, 665: 12054, 666: 18155, 667: 11814, 668: 11419, 669: 8865, 670: 10258, 671: 1745, 672: 17014, 673: 5987, 674: 4320, 675: 16691, 676: 662, 677: 326, 678: 1531, 679: 18944, 680: 5269, 681: 13287, 682: 12695, 683: 13798, 684: 735, 685: 18618, 686: 18516, 687: 10825, 688: 9364, 689: 10479, 690: 16109, 691: 9906, 692: 2565, 693: 17159, 694: 12932, 695: 3215, 696: 18171, 697: 16004, 698: 5292, 699: 10676, 700: 15107, 701: 13053, 702: 3054, 703: 15365, 704: 9607, 705: 13854, 706: 16167, 707: 4285, 708: 6511, 709: 14007, 710: 14675, 711: 12157, 712: 4795, 713: 15840, 714: 12743, 715: 12598, 716: 12413, 717: 11493, 718: 8226, 719: 11463, 720: 12942, 721: 9625, 722: 2121, 723: 14350, 724: 6856, 725: 7066, 726: 745, 727: 9444, 728: 8582, 729: 12462, 730: 19683, 731: 1674, 732: 2676, 733: 15970, 734: 7308, 735: 7321, 736: 19526, 737: 13779, 738: 10155, 739: 2095, 740: 8143, 741: 7934, 742: 9132, 743: 19118, 744: 18557, 745: 7804, 746: 18885, 747: 8547, 748: 4116, 749: 8385, 750: 17125, 751: 9684, 752: 4701, 753: 10003, 754: 6006, 755: 2920, 756: 2281, 757: 5643, 758: 17856, 759: 11973, 760: 19023, 761: 15832, 762: 8100, 763: 11527, 764: 19424, 765: 13095, 766: 15334, 767: 1933, 768: 2185, 769: 9360, 770: 16068, 771: 19932, 772: 11958, 773: 8999, 774: 11950, 775: 14617, 776: 5774, 777: 6929, 778: 1599, 779: 4670, 780: 2118, 781: 15479, 782: 5745, 783: 11834, 784: 314, 785: 19115, 786: 941, 787: 7319, 788: 18708, 789: 2726, 790: 6695, 791: 602, 792: 1231, 793: 6469, 794: 18409, 795: 1756, 796: 17080, 797: 14299, 798: 16762, 799: 19807, 800: 10038, 801: 9424, 802: 11970, 803: 9637, 804: 17674, 805: 11258, 806: 8645, 807: 17553, 808: 18725, 809: 17213, 810: 6710, 811: 5243, 812: 7022, 813: 18098, 814: 546, 815: 13339, 816: 12899, 817: 14427, 818: 8319, 819: 1294, 820: 863, 821: 1301, 822: 476, 823: 10088, 824: 7008, 825: 12806, 826: 1673, 827: 13164, 828: 54, 829: 18898, 830: 6625, 831: 15370, 832: 4891, 833: 5876, 834: 2033, 835: 8493, 836: 16629, 837: 1472, 838: 6812, 839: 14248, 840: 12952, 841: 13326, 842: 10106, 843: 13268, 844: 4188, 845: 763, 846: 6934, 847: 14862, 848: 13532, 849: 11034, 850: 7409, 851: 7657, 852: 16172, 853: 1090, 854: 8565, 855: 3806, 856: 8681, 857: 15891, 858: 11356, 859: 8464, 860: 6135, 861: 5, 862: 1073, 863: 14892, 864: 18439, 865: 18183, 866: 4649, 867: 16902, 868: 14688, 869: 12128, 870: 15768, 871: 9872, 872: 18228, 873: 3896, 874: 426, 875: 11117, 876: 10255, 877: 18304, 878: 16797, 879: 18125, 880: 16580, 881: 19691, 882: 16523, 883: 7408, 884: 112, 885: 7542, 886: 9227, 887: 11579, 888: 3399, 889: 1389, 890: 14294, 891: 12311, 892: 14474, 893: 12859, 894: 967, 895: 19874, 896: 19754, 897: 5974, 898: 19162, 899: 1554, 900: 12910, 901: 5357, 902: 643, 903: 1320, 904: 13359, 905: 11539, 906: 16809, 907: 7325, 908: 13924, 909: 7630, 910: 19114, 911: 15663, 912: 5168, 913: 2449, 914: 1586, 915: 10190, 916: 3568, 917: 3706, 918: 8459, 919: 4784, 920: 7212, 921: 6097, 922: 19760, 923: 16687, 924: 8896, 925: 10454, 926: 19751, 927: 17231, 928: 8365, 929: 5708, 930: 7119, 931: 15642, 932: 8001, 933: 17445, 934: 9250, 935: 2757, 936: 12394, 937: 18106, 938: 7794, 939: 513, 940: 4099, 941: 9434, 942: 11013, 943: 12682, 944: 6603, 945: 18792, 946: 9078, 947: 1032, 948: 16353, 949: 10538, 950: 3272, 951: 18481, 952: 13582, 953: 17020, 954: 5969, 955: 10162, 956: 9735, 957: 5019, 958: 6186, 959: 3847, 960: 7328, 961: 13423, 962: 17581, 963: 8283, 964: 4682, 965: 6533, 966: 659, 967: 18108, 968: 13610, 969: 19353, 970: 11728, 971: 8680, 972: 8654, 973: 14609, 974: 18029, 975: 3366, 976: 842, 977: 5484, 978: 12826, 979: 16276, 980: 4522, 981: 18237, 982: 12030, 983: 16915, 984: 6508, 985: 4140, 986: 11730, 987: 8852, 988: 10350, 989: 9748, 990: 162, 991: 14942, 992: 5069, 993: 10949, 994: 14019, 995: 10682, 996: 14869, 997: 4611, 998: 7284, 999: 2092, 1000: 2165, 1001: 10366, 1002: 14255, 1003: 5222, 1004: 557, 1005: 12063, 1006: 17043, 1007: 2256, 1008: 17807, 1009: 9529, 1010: 1245, 1011: 5739, 1012: 15659, 1013: 15394, 1014: 11720, 1015: 14669, 1016: 10000, 1017: 17916, 1018: 17628, 1019: 1275, 1020: 8115, 1021: 5046, 1022: 8758, 1023: 9851, 1024: 17270, 1025: 14125, 1026: 16459, 1027: 14542, 1028: 11283, 1029: 10377, 1030: 3462, 1031: 12500, 1032: 6555, 1033: 17330, 1034: 9458, 1035: 11856, 1036: 3074, 1037: 6997, 1038: 3256, 1039: 12044, 1040: 18765, 1041: 61, 1042: 15917, 1043: 2338, 1044: 1343, 1045: 18355, 1046: 7367, 1047: 5053, 1048: 4789, 1049: 7997, 1050: 6882, 1051: 6362, 1052: 4403, 1053: 10582, 1054: 18755, 1055: 4368, 1056: 4157, 1057: 17230, 1058: 536, 1059: 5333, 1060: 16655, 1061: 1604, 1062: 14457, 1063: 3760, 1064: 18842, 1065: 12684, 1066: 18383, 1067: 5503, 1068: 3807, 1069: 10655, 1070: 10856, 1071: 2117, 1072: 6680, 1073: 980, 1074: 174, 1075: 10734, 1076: 1329, 1077: 12074, 1078: 353, 1079: 16527, 1080: 4826, 1081: 1868, 1082: 18701, 1083: 17453, 1084: 3086, 1085: 8504, 1086: 1084, 1087: 1192, 1088: 11484, 1089: 9833, 1090: 16035, 1091: 11640, 1092: 7636, 1093: 18486, 1094: 6206, 1095: 18857, 1096: 6307, 1097: 18273, 1098: 11441, 1099: 6444, 1100: 9982, 1101: 13245, 1102: 9882, 1103: 245, 1104: 1929, 1105: 17550, 1106: 2728, 1107: 9524, 1108: 4007, 1109: 3752, 1110: 18136, 1111: 19097, 1112: 5588, 1113: 5244, 1114: 7692, 1115: 13398, 1116: 8739, 1117: 7012, 1118: 19833, 1119: 2486, 1120: 12207, 1121: 3040, 1122: 629, 1123: 19711, 1124: 529, 1125: 1229, 1126: 8653, 1127: 10727, 1128: 1732, 1129: 11866, 1130: 4449, 1131: 1497, 1132: 814, 1133: 1281, 1134: 6940, 1135: 805, 1136: 6708, 1137: 10723, 1138: 14916, 1139: 11594, 1140: 5008, 1141: 16349, 1142: 4266, 1143: 11253, 1144: 14608, 1145: 2065, 1146: 19587, 1147: 11323, 1148: 2850, 1149: 3022, 1150: 13362, 1151: 10099, 1152: 3734, 1153: 15102, 1154: 6059, 1155: 19252, 1156: 17130, 1157: 11943, 1158: 6122, 1159: 13119, 1160: 142, 1161: 18794, 1162: 10961, 1163: 13974, 1164: 46, 1165: 2069, 1166: 1713, 1167: 884, 1168: 17098, 1169: 16645, 1170: 1572, 1171: 17084, 1172: 10751, 1173: 7194, 1174: 4426, 1175: 6733, 1176: 520, 1177: 12217, 1178: 6525, 1179: 2021, 1180: 8446, 1181: 7513, 1182: 12471, 1183: 12133, 1184: 16430, 1185: 1891, 1186: 18914, 1187: 14246, 1188: 8253, 1189: 2816, 1190: 10104, 1191: 18466, 1192: 10105, 1193: 5274, 1194: 12356, 1195: 2274, 1196: 10867, 1197: 13196, 1198: 10319, 1199: 11325, 1200: 4523, 1201: 12669, 1202: 2241, 1203: 17720, 1204: 10511, 1205: 13120, 1206: 293, 1207: 13940, 1208: 13915, 1209: 1742, 1210: 14503, 1211: 876, 1212: 3798, 1213: 6217, 1214: 2664, 1215: 17328, 1216: 19830, 1217: 17374, 1218: 6891, 1219: 19187, 1220: 18257, 1221: 15703, 1222: 17210, 1223: 13044, 1224: 17799, 1225: 13696, 1226: 10398, 1227: 2896, 1228: 7896, 1229: 12096, 1230: 6722, 1231: 18339, 1232: 18653, 1233: 13325, 1234: 6056, 1235: 16406, 1236: 2155, 1237: 9290, 1238: 6595, 1239: 19025, 1240: 16208, 1241: 3148, 1242: 9575, 1243: 15744, 1244: 2378, 1245: 1980, 1246: 12552, 1247: 16368, 1248: 3087, 1249: 17569, 1250: 12108, 1251: 4424, 1252: 15737, 1253: 2312, 1254: 1313, 1255: 3224, 1256: 2769, 1257: 13173, 1258: 18723, 1259: 14808, 1260: 2738, 1261: 11084, 1262: 19070, 1263: 4746, 1264: 4945, 1265: 458, 1266: 1420, 1267: 15038, 1268: 4642, 1269: 526, 1270: 15018, 1271: 2875, 1272: 2413, 1273: 9847, 1274: 4877, 1275: 12673, 1276: 4013, 1277: 6528, 1278: 7070, 1279: 17428, 1280: 14659, 1281: 18007, 1282: 6065, 1283: 14653, 1284: 18741, 1285: 4466, 1286: 11794, 1287: 16161, 1288: 15710, 1289: 19537, 1290: 108, 1291: 9657, 1292: 5616, 1293: 8706, 1294: 2915, 1295: 10967, 1296: 15417, 1297: 15531, 1298: 18876, 1299: 9266, 1300: 8291, 1301: 6291, 1302: 8229, 1303: 19901, 1304: 5043, 1305: 17135, 1306: 3250, 1307: 14423, 1308: 6593, 1309: 13315, 1310: 13644, 1311: 12381, 1312: 6516, 1313: 3688, 1314: 1533, 1315: 1666, 1316: 13008, 1317: 12110, 1318: 4165, 1319: 19574, 1320: 9599, 1321: 13654, 1322: 2965, 1323: 19182, 1324: 10277, 1325: 5306, 1326: 15553, 1327: 17939, 1328: 7318, 1329: 5114, 1330: 19176, 1331: 7894, 1332: 3132, 1333: 19660, 1334: 7883, 1335: 19251, 1336: 15027, 1337: 18146, 1338: 12916, 1339: 14129, 1340: 16984, 1341: 8273, 1342: 16863, 1343: 4310, 1344: 7957, 1345: 1502, 1346: 8072, 1347: 3111, 1348: 4111, 1349: 17815, 1350: 12490, 1351: 16079, 1352: 9694, 1353: 14132, 1354: 9741, 1355: 6268, 1356: 5131, 1357: 10754, 1358: 18153, 1359: 4861, 1360: 4306, 1361: 9698, 1362: 10182, 1363: 19745, 1364: 19038, 1365: 7735, 1366: 1200, 1367: 16316, 1368: 14671, 1369: 5368, 1370: 19850, 1371: 719, 1372: 4222, 1373: 2758, 1374: 576, 1375: 15945, 1376: 11395, 1377: 187, 1378: 13919, 1379: 19619, 1380: 1108, 1381: 3039, 1382: 4654, 1383: 10600, 1384: 7705, 1385: 13166, 1386: 9179, 1387: 16340, 1388: 16522, 1389: 13010, 1390: 7287, 1391: 6266, 1392: 1403, 1393: 17044, 1394: 19387, 1395: 16392, 1396: 4128, 1397: 12210, 1398: 5362, 1399: 8993, 1400: 4005, 1401: 3310, 1402: 1293, 1403: 10932, 1404: 614, 1405: 16724, 1406: 18368, 1407: 10840, 1408: 5327, 1409: 18631, 1410: 2355, 1411: 9733, 1412: 9449, 1413: 13046, 1414: 5939, 1415: 13506, 1416: 4064, 1417: 13946, 1418: 15170, 1419: 7772, 1420: 3786, 1421: 3341, 1422: 6791, 1423: 16913, 1424: 11683, 1425: 8636, 1426: 11464, 1427: 16488, 1428: 2495, 1429: 3696, 1430: 9854, 1431: 11896, 1432: 19788, 1433: 2080, 1434: 14418, 1435: 12780, 1436: 12983, 1437: 18834, 1438: 19746, 1439: 19184, 1440: 6814, 1441: 11302, 1442: 18547, 1443: 6703, 1444: 1681, 1445: 9223, 1446: 4957, 1447: 15257, 1448: 260, 1449: 19785, 1450: 5538, 1451: 3449, 1452: 811, 1453: 8073, 1454: 9890, 1455: 14940, 1456: 4241, 1457: 18010, 1458: 10575, 1459: 481, 1460: 16856, 1461: 11873, 1462: 424, 1463: 9709, 1464: 2344, 1465: 11776, 1466: 6311, 1467: 7565, 1468: 4720, 1469: 8347, 1470: 14483, 1471: 14263, 1472: 13534, 1473: 11902, 1474: 8581, 1475: 19427, 1476: 2722, 1477: 4937, 1478: 6562, 1479: 5579, 1480: 15916, 1481: 7623, 1482: 16052, 1483: 14654, 1484: 3835, 1485: 7371, 1486: 11597, 1487: 4231, 1488: 11209, 1489: 4866, 1490: 956, 1491: 7539, 1492: 14899, 1493: 5214, 1494: 19971, 1495: 10301, 1496: 9125, 1497: 16602, 1498: 12055, 1499: 10289, 1500: 2040, 1501: 6869, 1502: 16158, 1503: 9630, 1504: 2727, 1505: 4174, 1506: 12654, 1507: 13957, 1508: 11697, 1509: 3818, 1510: 5427, 1511: 9608, 1512: 11715, 1513: 744, 1514: 7430, 1515: 15316, 1516: 5913, 1517: 6452, 1518: 18433, 1519: 16554, 1520: 8435, 1521: 19804, 1522: 5702, 1523: 14198, 1524: 10403, 1525: 177, 1526: 14819, 1527: 15628, 1528: 2483, 1529: 6124, 1530: 7965, 1531: 11187, 1532: 14064, 1533: 6212, 1534: 7517, 1535: 6715, 1536: 789, 1537: 10580, 1538: 12712, 1539: 18739, 1540: 1303, 1541: 16974, 1542: 9004, 1543: 15561, 1544: 18039, 1545: 7338, 1546: 4274, 1547: 15311, 1548: 13414, 1549: 9708, 1550: 16466, 1551: 8757, 1552: 14572, 1553: 1075, 1554: 7044, 1555: 9645, 1556: 6267, 1557: 5684, 1558: 15348, 1559: 16125, 1560: 18927, 1561: 3792, 1562: 9696, 1563: 14833, 1564: 12045, 1565: 5303, 1566: 2140, 1567: 13395, 1568: 2127, 1569: 2479, 1570: 9683, 1571: 3101, 1572: 9035, 1573: 14415, 1574: 14631, 1575: 2843, 1576: 12052, 1577: 2252, 1578: 15096, 1579: 3172, 1580: 13823, 1581: 7376, 1582: 14173, 1583: 15715, 1584: 19437, 1585: 11518, 1586: 19399, 1587: 642, 1588: 15161, 1589: 14982, 1590: 7515, 1591: 8371, 1592: 11494, 1593: 15088, 1594: 610, 1595: 5312, 1596: 10962, 1597: 9246, 1598: 6106, 1599: 2276, 1600: 5963, 1601: 9419, 1602: 4142, 1603: 331, 1604: 383, 1605: 19217, 1606: 16508, 1607: 14191, 1608: 8088, 1609: 18218, 1610: 10850, 1611: 16956, 1612: 13360, 1613: 15637, 1614: 1667, 1615: 5359, 1616: 15526, 1617: 14527, 1618: 3593, 1619: 10496, 1620: 1794, 1621: 11575, 1622: 12643, 1623: 6523, 1624: 9731, 1625: 14340, 1626: 16543, 1627: 13160, 1628: 19680, 1629: 5673, 1630: 19228, 1631: 4507, 1632: 4036, 1633: 17139, 1634: 15862, 1635: 17874, 1636: 18009, 1637: 11825, 1638: 3980, 1639: 6447, 1640: 7696, 1641: 5379, 1642: 18589, 1643: 12079, 1644: 4421, 1645: 8155, 1646: 12675, 1647: 8043, 1648: 3675, 1649: 3353, 1650: 14513, 1651: 19411, 1652: 4571, 1653: 14731, 1654: 16766, 1655: 19940, 1656: 9808, 1657: 15928, 1658: 411, 1659: 7959, 1660: 13265, 1661: 19288, 1662: 13756, 1663: 3229, 1664: 5037, 1665: 1830, 1666: 9600, 1667: 4860, 1668: 10915, 1669: 12520, 1670: 6971, 1671: 2721, 1672: 19075, 1673: 8066, 1674: 12912, 1675: 12982, 1676: 11639, 1677: 14610, 1678: 133, 1679: 17954, 1680: 8453, 1681: 10342, 1682: 6199, 1683: 15675, 1684: 19555, 1685: 6641, 1686: 14050, 1687: 49, 1688: 13233, 1689: 19268, 1690: 4489, 1691: 17881, 1692: 1783, 1693: 625, 1694: 9545, 1695: 15166, 1696: 15141, 1697: 12630, 1698: 3897, 1699: 3182, 1700: 16770, 1701: 19384, 1702: 7600, 1703: 12293, 1704: 4451, 1705: 17738, 1706: 8698, 1707: 3746, 1708: 12278, 1709: 7750, 1710: 5875, 1711: 607, 1712: 5001, 1713: 7864, 1714: 12026, 1715: 17952, 1716: 12188, 1717: 17748, 1718: 14593, 1719: 16492, 1720: 13195, 1721: 12701, 1722: 15894, 1723: 10983, 1724: 19626, 1725: 7343, 1726: 11619, 1727: 16274, 1728: 190, 1729: 15285, 1730: 6987, 1731: 14839, 1732: 888, 1733: 923, 1734: 17085, 1735: 11841, 1736: 12986, 1737: 3397, 1738: 2645, 1739: 1393, 1740: 18080, 1741: 11535, 1742: 18661, 1743: 8040, 1744: 17597, 1745: 6128, 1746: 6661, 1747: 2612, 1748: 17533, 1749: 6998, 1750: 3940, 1751: 9787, 1752: 9660, 1753: 15430, 1754: 18819, 1755: 19328, 1756: 17153, 1757: 17560, 1758: 19007, 1759: 10253, 1760: 8244, 1761: 12433, 1762: 15915, 1763: 13020, 1764: 17310, 1765: 5167, 1766: 11197, 1767: 12868, 1768: 13139, 1769: 5239, 1770: 5439, 1771: 8227, 1772: 11903, 1773: 3131, 1774: 11875, 1775: 13489, 1776: 17333, 1777: 14067, 1778: 14798, 1779: 5235, 1780: 6767, 1781: 5720, 1782: 1966, 1783: 4193, 1784: 2465, 1785: 2315, 1786: 4201, 1787: 9702, 1788: 6884, 1789: 1448, 1790: 6051, 1791: 2563, 1792: 11460, 1793: 9102, 1794: 5217, 1795: 5023, 1796: 615, 1797: 12533, 1798: 19979, 1799: 3677, 1800: 10928, 1801: 8855, 1802: 10448, 1803: 10236, 1804: 316, 1805: 13702, 1806: 2433, 1807: 3252, 1808: 12616, 1809: 8200, 1810: 7773, 1811: 3384, 1812: 19907, 1813: 14639, 1814: 19167, 1815: 4284, 1816: 16357, 1817: 95, 1818: 5874, 1819: 19914, 1820: 13976, 1821: 660, 1822: 13338, 1823: 14927, 1824: 2670, 1825: 17005, 1826: 7083, 1827: 12784, 1828: 11332, 1829: 10383, 1830: 14489, 1831: 7974, 1832: 13368, 1833: 12687, 1834: 11706, 1835: 14086, 1836: 15420, 1837: 14408, 1838: 12469, 1839: 8981, 1840: 14475, 1841: 18025, 1842: 890, 1843: 7378, 1844: 12322, 1845: 9002, 1846: 17629, 1847: 5918, 1848: 11289, 1849: 1795, 1850: 12498, 1851: 12382, 1852: 16041, 1853: 4430, 1854: 5006, 1855: 17182, 1856: 16105, 1857: 8293, 1858: 15480, 1859: 11621, 1860: 18154, 1861: 12505, 1862: 4211, 1863: 16007, 1864: 10874, 1865: 1166, 1866: 5904, 1867: 16150, 1868: 3409, 1869: 14770, 1870: 16162, 1871: 8907, 1872: 8798, 1873: 6019, 1874: 9152, 1875: 11468, 1876: 5880, 1877: 1461, 1878: 15591, 1879: 4356, 1880: 17337, 1881: 533, 1882: 11991, 1883: 6033, 1884: 16758, 1885: 3436, 1886: 6284, 1887: 19483, 1888: 7550, 1889: 10692, 1890: 523, 1891: 12897, 1892: 9578, 1893: 122, 1894: 13892, 1895: 7086, 1896: 1766, 1897: 11165, 1898: 9594, 1899: 17604, 1900: 18149, 1901: 7531, 1902: 18917, 1903: 4135, 1904: 4765, 1905: 7982, 1906: 18527, 1907: 19997, 1908: 18786, 1909: 15132, 1910: 18381, 1911: 3550, 1912: 5380, 1913: 2907, 1914: 9596, 1915: 9945, 1916: 15566, 1917: 15900, 1918: 19147, 1919: 5642, 1920: 13490, 1921: 19887, 1922: 17201, 1923: 6774, 1924: 1270, 1925: 5882, 1926: 71, 1927: 15127, 1928: 11675, 1929: 14311, 1930: 10535, 1931: 13059, 1932: 11157, 1933: 11207, 1934: 12134, 1935: 1597, 1936: 16601, 1937: 16680, 1938: 15541, 1939: 2020, 1940: 1516, 1941: 5959, 1942: 15664, 1943: 6393, 1944: 3099, 1945: 7299, 1946: 16653, 1947: 16595, 1948: 9147, 1949: 14848, 1950: 11023, 1951: 17942, 1952: 16482, 1953: 19183, 1954: 19419, 1955: 18210, 1956: 17051, 1957: 11372, 1958: 11311, 1959: 17785, 1960: 6336, 1961: 8872, 1962: 59, 1963: 14491, 1964: 16241, 1965: 19545, 1966: 12689, 1967: 7822, 1968: 13319, 1969: 12274, 1970: 3749, 1971: 6688, 1972: 15245, 1973: 15231, 1974: 19312, 1975: 1772, 1976: 13015, 1977: 7036, 1978: 7239, 1979: 5478, 1980: 1151, 1981: 16575, 1982: 3222, 1983: 2058, 1984: 14258, 1985: 1282, 1986: 12421, 1987: 8473, 1988: 10709, 1989: 7076, 1990: 14139, 1991: 3805, 1992: 9258, 1993: 12676, 1994: 13548, 1995: 10831, 1996: 13353, 1997: 2291, 1998: 14992, 1999: 1429, 2000: 9261, 2001: 1255, 2002: 6734, 2003: 15935, 2004: 8328, 2005: 17172, 2006: 11962, 2007: 7349, 2008: 7004, 2009: 8631, 2010: 16776, 2011: 17514, 2012: 9763, 2013: 4454, 2014: 17320, 2015: 6617, 2016: 14413, 2017: 16997, 2018: 470, 2019: 15143, 2020: 4966, 2021: 2900, 2022: 19443, 2023: 17932, 2024: 18387, 2025: 8519, 2026: 14884, 2027: 3505, 2028: 359, 2029: 17575, 2030: 16370, 2031: 6778, 2032: 4032, 2033: 917, 2034: 3890, 2035: 10802, 2036: 972, 2037: 15745, 2038: 1768, 2039: 16788, 2040: 12129, 2041: 13327, 2042: 6041, 2043: 782, 2044: 11917, 2045: 13741, 2046: 10456, 2047: 461, 2048: 11674, 2049: 17204, 2050: 3046, 2051: 15211, 2052: 10147, 2053: 3286, 2054: 10895, 2055: 12395, 2056: 7476, 2057: 16570, 2058: 2623, 2059: 10148, 2060: 515, 2061: 4663, 2062: 18954, 2063: 18417, 2064: 16582, 2065: 912, 2066: 6111, 2067: 10133, 2068: 1386, 2069: 11291, 2070: 2923, 2071: 2375, 2072: 1800, 2073: 10981, 2074: 9626, 2075: 18113, 2076: 4728, 2077: 2917, 2078: 17540, 2079: 11212, 2080: 6274, 2081: 17636, 2082: 4024, 2083: 13057, 2084: 12008, 2085: 17926, 2086: 16536, 2087: 7652, 2088: 13700, 2089: 18561, 2090: 11495, 2091: 5132, 2092: 17710, 2093: 12367, 2094: 619, 2095: 8513, 2096: 9281, 2097: 13904, 2098: 19480, 2099: 2562, 2100: 1770, 2101: 11551, 2102: 6191, 2103: 1458, 2104: 3955, 2105: 15094, 2106: 5535, 2107: 6995, 2108: 19661, 2109: 12737, 2110: 18721, 2111: 4798, 2112: 13721, 2113: 11399, 2114: 6645, 2115: 6043, 2116: 18413, 2117: 12219, 2118: 8398, 2119: 18130, 2120: 15983, 2121: 7477, 2122: 2263, 2123: 1148, 2124: 13866, 2125: 13201, 2126: 6367, 2127: 15066, 2128: 13379, 2129: 5817, 2130: 18902, 2131: 1968, 2132: 18034, 2133: 13669, 2134: 7095, 2135: 6095, 2136: 7930, 2137: 11918, 2138: 6310, 2139: 15883, 2140: 16361, 2141: 19130, 2142: 10998, 2143: 13542, 2144: 1408, 2145: 645, 2146: 469, 2147: 1197, 2148: 17554, 2149: 14396, 2150: 14143, 2151: 4626, 2152: 8169, 2153: 490, 2154: 7921, 2155: 4264, 2156: 8042, 2157: 17478, 2158: 17096, 2159: 8184, 2160: 18811, 2161: 10837, 2162: 5883, 2163: 8049, 2164: 14871, 2165: 5994, 2166: 18572, 2167: 4971, 2168: 11633, 2169: 4469, 2170: 8692, 2171: 16537, 2172: 12408, 2173: 17600, 2174: 1005, 2175: 230, 2176: 16547, 2177: 13948, 2178: 16515, 2179: 11643, 2180: 13673, 2181: 14607, 2182: 1257, 2183: 6540, 2184: 17571, 2185: 6341, 2186: 6651, 2187: 11285, 2188: 4352, 2189: 14202, 2190: 13857, 2191: 19061, 2192: 9565, 2193: 9354, 2194: 12571, 2195: 17739, 2196: 4086, 2197: 14313, 2198: 5411, 2199: 7023, 2200: 8450, 2201: 16360, 2202: 8099, 2203: 4965, 2204: 16478, 2205: 12349, 2206: 18097, 2207: 5790, 2208: 12181, 2209: 6149, 2210: 10315, 2211: 17562, 2212: 7844, 2213: 1153, 2214: 8671, 2215: 2421, 2216: 5854, 2217: 12345, 2218: 10225, 2219: 8485, 2220: 11919, 2221: 13557, 2222: 18265, 2223: 16407, 2224: 3163, 2225: 9317, 2226: 19662, 2227: 8734, 2228: 10241, 2229: 14186, 2230: 16879, 2231: 6483, 2232: 13033, 2233: 195, 2234: 19870, 2235: 15602, 2236: 4520, 2237: 1167, 2238: 13484, 2239: 15833, 2240: 18900, 2241: 12829, 2242: 2468, 2243: 5635, 2244: 19409, 2245: 9191, 2246: 12492, 2247: 47, 2248: 16308, 2249: 19425, 2250: 8474, 2251: 16000, 2252: 17962, 2253: 15221, 2254: 11823, 2255: 18212, 2256: 19890, 2257: 11520, 2258: 6585, 2259: 11198, 2260: 15756, 2261: 1463, 2262: 6330, 2263: 7063, 2264: 442, 2265: 2036, 2266: 19065, 2267: 17148, 2268: 16581, 2269: 18836, 2270: 12135, 2271: 2848, 2272: 14625, 2273: 7708, 2274: 14273, 2275: 18078, 2276: 1088, 2277: 8188, 2278: 8526, 2279: 1827, 2280: 6320, 2281: 3658, 2282: 5496, 2283: 18909, 2284: 804, 2285: 9327, 2286: 832, 2287: 19985, 2288: 5182, 2289: 14996, 2290: 19613, 2291: 13218, 2292: 12058, 2293: 17756, 2294: 18828, 2295: 7429, 2296: 7741, 2297: 3693, 2298: 15795, 2299: 16989, 2300: 3689, 2301: 349, 2302: 16065, 2303: 13793, 2304: 4010, 2305: 3370, 2306: 8237, 2307: 9519, 2308: 3944, 2309: 17923, 2310: 7478, 2311: 8932, 2312: 8799, 2313: 5706, 2314: 14277, 2315: 13936, 2316: 8930, 2317: 10502, 2318: 19469, 2319: 13874, 2320: 2870, 2321: 960, 2322: 10487, 2323: 15039, 2324: 10972, 2325: 2023, 2326: 9767, 2327: 6988, 2328: 115, 2329: 1787, 2330: 10058, 2331: 10525, 2332: 3441, 2333: 6118, 2334: 16134, 2335: 5012, 2336: 1347, 2337: 15940, 2338: 978, 2339: 344, 2340: 11301, 2341: 8035, 2342: 9745, 2343: 2507, 2344: 11313, 2345: 8335, 2346: 15741, 2347: 5428, 2348: 1765, 2349: 13851, 2350: 8409, 2351: 13997, 2352: 9992, 2353: 10109, 2354: 3586, 2355: 8807, 2356: 17436, 2357: 3349, 2358: 12493, 2359: 16252, 2360: 15654, 2361: 11588, 2362: 16838, 2363: 8838, 2364: 17321, 2365: 12004, 2366: 14926, 2367: 11791, 2368: 19450, 2369: 17495, 2370: 19478, 2371: 4176, 2372: 1841, 2373: 3170, 2374: 5325, 2375: 18772, 2376: 15460, 2377: 453, 2378: 13699, 2379: 16841, 2380: 3772, 2381: 5957, 2382: 19960, 2383: 4173, 2384: 2497, 2385: 3362, 2386: 12742, 2387: 10425, 2388: 2255, 2389: 16157, 2390: 2584, 2391: 19476, 2392: 3056, 2393: 8766, 2394: 15076, 2395: 4637, 2396: 3849, 2397: 7446, 2398: 13826, 2399: 12640, 2400: 197, 2401: 15767, 2402: 19524, 2403: 4350, 2404: 5364, 2405: 3365, 2406: 3055, 2407: 2440, 2408: 6890, 2409: 4612, 2410: 11977, 2411: 16670, 2412: 16431, 2413: 2330, 2414: 5772, 2415: 10656, 2416: 8396, 2417: 3973, 2418: 18611, 2419: 1107, 2420: 3727, 2421: 4536, 2422: 18534, 2423: 4159, 2424: 3878, 2425: 16223, 2426: 2280, 2427: 1051, 2428: 4561, 2429: 961, 2430: 1391, 2431: 8404, 2432: 19775, 2433: 5074, 2434: 19458, 2435: 16017, 2436: 9422, 2437: 5193, 2438: 13431, 2439: 17813, 2440: 4486, 2441: 13497, 2442: 19862, 2443: 18646, 2444: 8559, 2445: 7653, 2446: 3989, 2447: 16548, 2448: 16137, 2449: 2300, 2450: 1398, 2451: 11703, 2452: 18892, 2453: 15764, 2454: 18440, 2455: 2867, 2456: 17401, 2457: 19481, 2458: 19958, 2459: 8952, 2460: 16429, 2461: 11507, 2462: 7818, 2463: 211, 2464: 2335, 2465: 4245, 2466: 8707, 2467: 19500, 2468: 17794, 2469: 12209, 2470: 7884, 2471: 14494, 2472: 12918, 2473: 18359, 2474: 1776, 2475: 7382, 2476: 3861, 2477: 10298, 2478: 17801, 2479: 7661, 2480: 19780, 2481: 3975, 2482: 10450, 2483: 11741, 2484: 6866, 2485: 15852, 2486: 5964, 2487: 17718, 2488: 12442, 2489: 10993, 2490: 13200, 2491: 7253, 2492: 12020, 2493: 19945, 2494: 14095, 2495: 3968, 2496: 10938, 2497: 10478, 2498: 1462, 2499: 9129, 2500: 14747, 2501: 13415, 2502: 13202, 2503: 11593, 2504: 1989, 2505: 6563, 2506: 3666, 2507: 947, 2508: 12577, 2509: 3498, 2510: 14692, 2511: 9096, 2512: 4694, 2513: 2607, 2514: 16015, 2515: 10308, 2516: 3956, 2517: 1680, 2518: 18764, 2519: 6947, 2520: 4688, 2521: 10149, 2522: 7238, 2523: 7780, 2524: 17140, 2525: 13963, 2526: 11876, 2527: 5105, 2528: 6601, 2529: 4940, 2530: 2328, 2531: 14753, 2532: 6570, 2533: 13959, 2534: 635, 2535: 17358, 2536: 738, 2537: 4409, 2538: 19052, 2539: 2340, 2540: 16988, 2541: 18184, 2542: 8580, 2543: 984, 2544: 3297, 2545: 8571, 2546: 19407, 2547: 14072, 2548: 5356, 2549: 10210, 2550: 1171, 2551: 1689, 2552: 11547, 2553: 17253, 2554: 1159, 2555: 9333, 2556: 14401, 2557: 6457, 2558: 17811, 2559: 9091, 2560: 15213, 2561: 5212, 2562: 9558, 2563: 2139, 2564: 8588, 2565: 4749, 2566: 6372, 2567: 13869, 2568: 9765, 2569: 7244, 2570: 11062, 2571: 9482, 2572: 6955, 2573: 525, 2574: 2494, 2575: 1455, 2576: 3306, 2577: 3889, 2578: 17180, 2579: 19179, 2580: 2323, 2581: 13473, 2582: 16053, 2583: 8361, 2584: 2671, 2585: 6129, 2586: 492, 2587: 10421, 2588: 15033, 2589: 9279, 2590: 18910, 2591: 7824, 2592: 10671, 2593: 5981, 2594: 3691, 2595: 19794, 2596: 18255, 2597: 1082, 2598: 6782, 2599: 8888, 2600: 15015, 2601: 12519, 2602: 12783, 2603: 16571, 2604: 9299, 2605: 3596, 2606: 19894, 2607: 12314, 2608: 12632, 2609: 4855, 2610: 15446, 2611: 18001, 2612: 10320, 2613: 13274, 2614: 19332, 2615: 2007, 2616: 1438, 2617: 19014, 2618: 11788, 2619: 5247, 2620: 210, 2621: 6478, 2622: 6513, 2623: 3486, 2624: 6224, 2625: 16662, 2626: 5600, 2627: 7787, 2628: 9598, 2629: 16477, 2630: 17866, 2631: 18585, 2632: 928, 2633: 4419, 2634: 7909, 2635: 10381, 2636: 1459, 2637: 10971, 2638: 18990, 2639: 14358, 2640: 18692, 2641: 17269, 2642: 12105, 2643: 15398, 2644: 6959, 2645: 9462, 2646: 4040, 2647: 6460, 2648: 5853, 2649: 17931, 2650: 19650, 2651: 13941, 2652: 9046, 2653: 5355, 2654: 4312, 2655: 9587, 2656: 15400, 2657: 4929, 2658: 16291, 2659: 10907, 2660: 15328, 2661: 1344, 2662: 4420, 2663: 17297, 2664: 4413, 2665: 6638, 2666: 15901, 2667: 12159, 2668: 4289, 2669: 15327, 2670: 16374, 2671: 15286, 2672: 10361, 2673: 6154, 2674: 16628, 2675: 11599, 2676: 3027, 2677: 573, 2678: 2184, 2679: 16358, 2680: 8622, 2681: 8684, 2682: 2254, 2683: 7742, 2684: 12399, 2685: 8738, 2686: 18843, 2687: 15645, 2688: 303, 2689: 12202, 2690: 8728, 2691: 13366, 2692: 10968, 2693: 15169, 2694: 11124, 2695: 10317, 2696: 7511, 2697: 14773, 2698: 11392, 2699: 6288, 2700: 105, 2701: 17694, 2702: 19408, 2703: 8783, 2704: 957, 2705: 6406, 2706: 13316, 2707: 2064, 2708: 19568, 2709: 6566, 2710: 10455, 2711: 4774, 2712: 5630, 2713: 4816, 2714: 1288, 2715: 18193, 2716: 19821, 2717: 10984, 2718: 7041, 2719: 7310, 2720: 1316, 2721: 12763, 2722: 10329, 2723: 12570, 2724: 2320, 2725: 14094, 2726: 8720, 2727: 636, 2728: 13891, 2729: 18405, 2730: 17892, 2731: 11299, 2732: 18278, 2733: 7840, 2734: 17034, 2735: 16917, 2736: 2319, 2737: 9653, 2738: 12602, 2739: 1859, 2740: 17991, 2741: 3572, 2742: 8524, 2743: 1335, 2744: 13048, 2745: 18678, 2746: 9898, 2747: 2891, 2748: 10054, 2749: 4570, 2750: 3967, 2751: 18823, 2752: 6184, 2753: 3289, 2754: 15059, 2755: 12451, 2756: 4935, 2757: 1585, 2758: 4555, 2759: 2215, 2760: 5198, 2761: 5553, 2762: 16659, 2763: 2407, 2764: 19180, 2765: 18456, 2766: 14324, 2767: 8696, 2768: 5750, 2769: 2598, 2770: 17114, 2771: 14447, 2772: 3010, 2773: 2094, 2774: 7109, 2775: 13561, 2776: 18507, 2777: 15804, 2778: 15299, 2779: 948, 2780: 7456, 2781: 7561, 2782: 15453, 2783: 12931, 2784: 16163, 2785: 10639, 2786: 10585, 2787: 2368, 2788: 16339, 2789: 5246, 2790: 15565, 2791: 19761, 2792: 8503, 2793: 16225, 2794: 2217, 2795: 1563, 2796: 4959, 2797: 7065, 2798: 17168, 2799: 12773, 2800: 13538, 2801: 14268, 2802: 7749, 2803: 13581, 2804: 4999, 2805: 19082, 2806: 1659, 2807: 12488, 2808: 12831, 2809: 550, 2810: 3784, 2811: 16611, 2812: 1763, 2813: 13671, 2814: 9330, 2815: 3169, 2816: 14567, 2817: 4643, 2818: 1030, 2819: 2561, 2820: 14316, 2821: 1733, 2822: 15810, 2823: 17031, 2824: 1910, 2825: 17128, 2826: 3632, 2827: 1009, 2828: 19131, 2829: 5742, 2830: 2608, 2831: 16916, 2832: 19306, 2833: 15071, 2834: 2822, 2835: 18054, 2836: 19278, 2837: 11007, 2838: 637, 2839: 10440, 2840: 2377, 2841: 6411, 2842: 9701, 2843: 250, 2844: 11540, 2845: 2436, 2846: 2729, 2847: 12401, 2848: 13609, 2849: 18070, 2850: 6571, 2851: 16264, 2852: 18380, 2853: 4134, 2854: 13885, 2855: 2753, 2856: 5536, 2857: 14459, 2858: 8472, 2859: 6446, 2860: 9646, 2861: 15419, 2862: 10264, 2863: 13791, 2864: 6960, 2865: 10925, 2866: 13794, 2867: 1801, 2868: 12966, 2869: 2174, 2870: 12940, 2871: 9803, 2872: 19790, 2873: 18563, 2874: 6060, 2875: 17580, 2876: 15497, 2877: 19309, 2878: 17206, 2879: 14243, 2880: 883, 2881: 11732, 2882: 16025, 2883: 12972, 2884: 15442, 2885: 9619, 2886: 223, 2887: 16385, 2888: 18837, 2889: 15188, 2890: 16951, 2891: 11319, 2892: 5968, 2893: 3774, 2894: 14193, 2895: 8890, 2896: 14063, 2897: 1864, 2898: 18867, 2899: 11964, 2900: 18225, 2901: 9517, 2902: 13732, 2903: 19285, 2904: 9308, 2905: 18967, 2906: 15718, 2907: 2390, 2908: 143, 2909: 13970, 2910: 12240, 2911: 6735, 2912: 1138, 2913: 12937, 2914: 5218, 2915: 14130, 2916: 7051, 2917: 8502, 2918: 19614, 2919: 7736, 2920: 17149, 2921: 8326, 2922: 20, 2923: 3477, 2924: 15849, 2925: 242, 2926: 3598, 2927: 16498, 2928: 13763, 2929: 16933, 2930: 11145, 2931: 8481, 2932: 9641, 2933: 2114, 2934: 15495, 2935: 6886, 2936: 296, 2937: 3616, 2938: 3483, 2939: 5399, 2940: 12085, 2941: 15014, 2942: 12703, 2943: 14137, 2944: 15350, 2945: 13672, 2946: 12080, 2947: 5973, 2948: 1684, 2949: 6556, 2950: 10617, 2951: 18269, 2952: 15130, 2953: 19725, 2954: 17545, 2955: 10969, 2956: 4554, 2957: 10599, 2958: 807, 2959: 2537, 2960: 5767, 2961: 12529, 2962: 11761, 2963: 3430, 2964: 5672, 2965: 8202, 2966: 16747, 2967: 15494, 2968: 7961, 2969: 3231}\n",
      "{0: 1, 1: 0, 2: 4, 3: 3, 4: 2}\n"
     ]
    }
   ],
   "source": [
    "print(company_mapping)\n",
    "print(type_mapping)\n",
    "#print(types.size)\n",
    "#test_data['company'].map(company_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>company</th>\n",
       "      <th>is_local</th>\n",
       "      <th>type</th>\n",
       "      <th>fin_1</th>\n",
       "      <th>fin_2</th>\n",
       "      <th>fin_3</th>\n",
       "      <th>fin_4</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>160000</td>\n",
       "      <td>39.284310</td>\n",
       "      <td>-76.735350</td>\n",
       "      <td>18187</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>113033.389907</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>270.906219</td>\n",
       "      <td>31222.780176</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>160001</td>\n",
       "      <td>36.758509</td>\n",
       "      <td>-76.344861</td>\n",
       "      <td>11208</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-87239.590275</td>\n",
       "      <td>73759.387510</td>\n",
       "      <td>759.194862</td>\n",
       "      <td>237587.544996</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>160002</td>\n",
       "      <td>43.402802</td>\n",
       "      <td>-75.217100</td>\n",
       "      <td>7437</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>-122084.498620</td>\n",
       "      <td>15528.109943</td>\n",
       "      <td>1039.655934</td>\n",
       "      <td>29612.346982</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>160003</td>\n",
       "      <td>41.871160</td>\n",
       "      <td>-87.848570</td>\n",
       "      <td>17362</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>87355.127256</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>214.594205</td>\n",
       "      <td>163526.475818</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>160004</td>\n",
       "      <td>42.161296</td>\n",
       "      <td>-88.129184</td>\n",
       "      <td>11515</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>33014.437946</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>379.819724</td>\n",
       "      <td>67499.397999</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39995</td>\n",
       "      <td>199995</td>\n",
       "      <td>35.241600</td>\n",
       "      <td>-80.983740</td>\n",
       "      <td>11640</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>194648.093228</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>95.701485</td>\n",
       "      <td>37584.380280</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39996</td>\n",
       "      <td>199996</td>\n",
       "      <td>35.241730</td>\n",
       "      <td>-80.983750</td>\n",
       "      <td>11849</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-53202.007008</td>\n",
       "      <td>9641.082811</td>\n",
       "      <td>653.516413</td>\n",
       "      <td>189604.463353</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39997</td>\n",
       "      <td>199997</td>\n",
       "      <td>35.290596</td>\n",
       "      <td>-80.756953</td>\n",
       "      <td>3987</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-102398.568309</td>\n",
       "      <td>47105.929570</td>\n",
       "      <td>863.135873</td>\n",
       "      <td>26231.880089</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39998</td>\n",
       "      <td>199998</td>\n",
       "      <td>35.204460</td>\n",
       "      <td>-80.720190</td>\n",
       "      <td>12287</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32066.188506</td>\n",
       "      <td>6659.705140</td>\n",
       "      <td>363.861756</td>\n",
       "      <td>116288.412218</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39999</td>\n",
       "      <td>199999</td>\n",
       "      <td>35.222470</td>\n",
       "      <td>-80.847460</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35049.846910</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>394.187736</td>\n",
       "      <td>18465.764838</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40000 rows  11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0   latitude  longitude  company  is_local  type  \\\n",
       "0          160000  39.284310 -76.735350    18187         1     1   \n",
       "1          160001  36.758509 -76.344861    11208         0     0   \n",
       "2          160002  43.402802 -75.217100     7437         1     4   \n",
       "3          160003  41.871160 -87.848570    17362         0     1   \n",
       "4          160004  42.161296 -88.129184    11515         0     3   \n",
       "...           ...        ...        ...      ...       ...   ...   \n",
       "39995      199995  35.241600 -80.983740    11640         0     3   \n",
       "39996      199996  35.241730 -80.983750    11849         0     3   \n",
       "39997      199997  35.290596 -80.756953     3987         0     3   \n",
       "39998      199998  35.204460 -80.720190    12287         0     0   \n",
       "39999      199999  35.222470 -80.847460        7         0     3   \n",
       "\n",
       "               fin_1         fin_2        fin_3          fin_4  target  \n",
       "0      113033.389907      0.000000   270.906219   31222.780176       0  \n",
       "1      -87239.590275  73759.387510   759.194862  237587.544996       1  \n",
       "2     -122084.498620  15528.109943  1039.655934   29612.346982       0  \n",
       "3       87355.127256      0.000000   214.594205  163526.475818       1  \n",
       "4       33014.437946      0.000000   379.819724   67499.397999       1  \n",
       "...              ...           ...          ...            ...     ...  \n",
       "39995  194648.093228      0.000000    95.701485   37584.380280       1  \n",
       "39996  -53202.007008   9641.082811   653.516413  189604.463353       0  \n",
       "39997 -102398.568309  47105.929570   863.135873   26231.880089       0  \n",
       "39998   32066.188506   6659.705140   363.861756  116288.412218       1  \n",
       "39999   35049.846910      0.000000   394.187736   18465.764838       1  \n",
       "\n",
       "[40000 rows x 11 columns]"
      ]
     },
     "execution_count": 479,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.replace('company', company_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of        Unnamed: 0   latitude  longitude  company  is_local  type  \\\n",
       "0          160000  39.284310 -76.735350    18187         1     1   \n",
       "1          160001  36.758509 -76.344861    11208         0     0   \n",
       "2          160002  43.402802 -75.217100     7437         1     4   \n",
       "3          160003  41.871160 -87.848570    17362         0     1   \n",
       "4          160004  42.161296 -88.129184    11515         0     3   \n",
       "...           ...        ...        ...      ...       ...   ...   \n",
       "39995      199995  35.241600 -80.983740    11640         0     3   \n",
       "39996      199996  35.241730 -80.983750    11849         0     3   \n",
       "39997      199997  35.290596 -80.756953     3987         0     3   \n",
       "39998      199998  35.204460 -80.720190    12287         0     0   \n",
       "39999      199999  35.222470 -80.847460        7         0     3   \n",
       "\n",
       "               fin_1         fin_2        fin_3          fin_4  target  \\\n",
       "0      113033.389907      0.000000   270.906219   31222.780176       0   \n",
       "1      -87239.590275  73759.387510   759.194862  237587.544996       1   \n",
       "2     -122084.498620  15528.109943  1039.655934   29612.346982       0   \n",
       "3       87355.127256      0.000000   214.594205  163526.475818       1   \n",
       "4       33014.437946      0.000000   379.819724   67499.397999       1   \n",
       "...              ...           ...          ...            ...     ...   \n",
       "39995  194648.093228      0.000000    95.701485   37584.380280       1   \n",
       "39996  -53202.007008   9641.082811   653.516413  189604.463353       0   \n",
       "39997 -102398.568309  47105.929570   863.135873   26231.880089       0   \n",
       "39998   32066.188506   6659.705140   363.861756  116288.412218       1   \n",
       "39999   35049.846910      0.000000   394.187736   18465.764838       1   \n",
       "\n",
       "       cluster  \n",
       "0           72  \n",
       "1          183  \n",
       "2           78  \n",
       "3          242  \n",
       "4           95  \n",
       "...        ...  \n",
       "39995      223  \n",
       "39996      223  \n",
       "39997      265  \n",
       "39998      294  \n",
       "39999      144  \n",
       "\n",
       "[40000 rows x 12 columns]>"
      ]
     },
     "execution_count": 474,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "company\n",
       "-1        4565\n",
       " 11         33\n",
       " 20          3\n",
       " 30         10\n",
       " 46         18\n",
       "          ... \n",
       " 19971      10\n",
       " 19974      45\n",
       " 19979      22\n",
       " 19985      11\n",
       " 19997       6\n",
       "Name: Unnamed: 0, Length: 3683, dtype: int64"
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "companies = train_data.groupby('company').count().iloc[:,0]\n",
    "companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "company\n",
       "-1        4565\n",
       " 11         33\n",
       " 46         18\n",
       " 61         34\n",
       " 68        194\n",
       "          ... \n",
       " 19958      13\n",
       " 19960      14\n",
       " 19974      45\n",
       " 19979      22\n",
       " 19985      11\n",
       "Name: Unnamed: 0, Length: 1381, dtype: int64"
      ]
     },
     "execution_count": 482,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "needed_companies = companies[companies > 10]\n",
    "needed_companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_cluster(data):\n",
    "    features = data[['latitude', 'longitude']]\n",
    "    kmeans_clustering = KMeans(\n",
    "    init=\"random\",\n",
    "    n_clusters=300,\n",
    "    n_init=10,\n",
    "    max_iter=300,\n",
    "    random_state=42\n",
    "    )\n",
    "    kmeans_clustering.fit(features)\n",
    "    labels = kmeans_clustering.labels_\n",
    "    data['cluster'] = labels\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_comp(data):\n",
    "    data.loc[data.company <= 10, ('company')] = -1\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_inputs(data):\n",
    "    data = input_cluster(data)\n",
    "    data = input_comp(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.drop(columns=train_data.columns[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.drop(columns=['latitude', 'longitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = train_data.drop(columns=['target']), train_data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(144000, 8)"
      ]
     },
     "execution_count": 492,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "opt = Adam(learning_rate=1e-4)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 144000 samples\n",
      "Epoch 1/10\n",
      "   128/144000 [..............................] - ETA: 1:23:01"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": " indices[1,0] = 15581 is not in [0, 3683)\n\t [[node model_23/embedding_45/embedding_lookup (defined at <ipython-input-531-c000603f0673>:10) ]] [Op:__inference_distributed_function_20910]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node model_23/embedding_45/embedding_lookup:\n model_23/embedding_45/embedding_lookup/20155 (defined at D:\\Anaconda3\\lib\\contextlib.py:112)\n\nFunction call stack:\ndistributed_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-531-c000603f0673>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;33m{\u001b[0m\u001b[1;34m\"targets\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m )\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    127\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 98\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    630\u001b[0m         \u001b[1;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    631\u001b[0m         \u001b[1;31m# stateless function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 632\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    633\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2361\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2363\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2365\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1611\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1613\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m     \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     keras_symbolic_tensors = [\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m:  indices[1,0] = 15581 is not in [0, 3683)\n\t [[node model_23/embedding_45/embedding_lookup (defined at <ipython-input-531-c000603f0673>:10) ]] [Op:__inference_distributed_function_20910]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node model_23/embedding_45/embedding_lookup:\n model_23/embedding_45/embedding_lookup/20155 (defined at D:\\Anaconda3\\lib\\contextlib.py:112)\n\nFunction call stack:\ndistributed_function\n"
     ]
    }
   ],
   "source": [
    "features = X_train[['fin_1', 'fin_2', 'fin_3', 'fin_4', 'is_local']]\n",
    "company = X_train['company']\n",
    "types = X_train['type']\n",
    "location = X_train['cluster']\n",
    "targets = y_train[y_train.columns[0]]\n",
    "model.fit(\n",
    "    {\"features\": features, \"company\": company, \"type\": types, \"location\": location},\n",
    "    {\"targets\": targets},\n",
    "    epochs=10,\n",
    "    batch_size=128,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10548     1\n",
      "40731     0\n",
      "152747    1\n",
      "140244    1\n",
      "21626     1\n",
      "         ..\n",
      "97890     0\n",
      "155390    1\n",
      "138320    0\n",
      "47694     0\n",
      "36783     0\n",
      "Name: target, Length: 144000, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y_train[y_train.columns[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
